{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edf9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading wine quality dataset...\")\n",
    "try:\n",
    "    import kagglehub\n",
    "    path = kagglehub.dataset_download(\"yasserh/wine-quality-dataset\")\n",
    "    df = pd.read_csv(f\"{path}/WineQT.csv\")\n",
    "    print(\"✓ Dataset loaded from Kaggle\")\n",
    "except:\n",
    "    try:\n",
    "        df = pd.read_csv(\"WineQT.csv\")\n",
    "        print(\"✓ Dataset loaded from local file\")\n",
    "    except:\n",
    "        print(\"⚠ Could not load dataset. Please ensure WineQT.csv is in the current directory\")\n",
    "        print(\"  or install kagglehub: pip install kagglehub\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3380da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNFromScratch:\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbors classifier implemented from scratch\n",
    "    \"\"\"\n",
    "    def __init__(self, k=5):\n",
    "        \"\"\"\n",
    "        Initialize KNN classifier\n",
    "        \n",
    "        Parameters:\n",
    "        k: number of neighbors to consider\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Store training data\n",
    "        \n",
    "        Parameters:\n",
    "        X_train: Training features (n_samples, n_features)\n",
    "        y_train: Training labels (n_samples,)\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Calculate Euclidean distance between two points\n",
    "        \n",
    "        Parameters:\n",
    "        x1: First point\n",
    "        x2: Second point\n",
    "        \n",
    "        Returns:\n",
    "        distance: Euclidean distance\n",
    "        \"\"\"\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def manhattan_distance(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Calculate Manhattan distance between two points\n",
    "        \n",
    "        Parameters:\n",
    "        x1: First point\n",
    "        x2: Second point\n",
    "        \n",
    "        Returns:\n",
    "        distance: Manhattan distance\n",
    "        \"\"\"\n",
    "        return np.sum(np.abs(x1 - x2))\n",
    "    \n",
    "    def predict_single(self, x_test):\n",
    "        \"\"\"\n",
    "        Predict class for a single test point\n",
    "        \n",
    "        Parameters:\n",
    "        x_test: Test point (n_features,)\n",
    "        \n",
    "        Returns:\n",
    "        prediction: Predicted class\n",
    "        \"\"\"\n",
    "        # Calculate distances to all training points\n",
    "        distances = []\n",
    "        for i, x_train in enumerate(self.X_train):\n",
    "            dist = self.euclidean_distance(x_test, x_train)\n",
    "            distances.append((dist, self.y_train[i]))\n",
    "        \n",
    "        # Sort by distance and get k nearest neighbors\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_nearest = distances[:self.k]\n",
    "        \n",
    "        # Get the labels of k nearest neighbors\n",
    "        k_nearest_labels = [label for _, label in k_nearest]\n",
    "        \n",
    "        # Vote for the most common class\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict classes for multiple test points\n",
    "        \n",
    "        Parameters:\n",
    "        X_test: Test features (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        predictions: Array of predictions\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x_test in X_test:\n",
    "            predictions.append(self.predict_single(x_test))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for test points\n",
    "        \n",
    "        Parameters:\n",
    "        X_test: Test features (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        probabilities: Array of class probabilities\n",
    "        \"\"\"\n",
    "        unique_classes = np.unique(self.y_train)\n",
    "        probabilities = []\n",
    "        \n",
    "        for x_test in X_test:\n",
    "            # Calculate distances to all training points\n",
    "            distances = []\n",
    "            for i, x_train in enumerate(self.X_train):\n",
    "                dist = self.euclidean_distance(x_test, x_train)\n",
    "                distances.append((dist, self.y_train[i]))\n",
    "            \n",
    "            # Sort by distance and get k nearest neighbors\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            k_nearest = distances[:self.k]\n",
    "            \n",
    "            # Count occurrences of each class\n",
    "            k_nearest_labels = [label for _, label in k_nearest]\n",
    "            class_counts = Counter(k_nearest_labels)\n",
    "            \n",
    "            # Calculate probabilities\n",
    "            probs = []\n",
    "            for cls in unique_classes:\n",
    "                probs.append(class_counts.get(cls, 0) / self.k)\n",
    "            probabilities.append(probs)\n",
    "            \n",
    "        return np.array(probabilities)\n",
    "\n",
    "\n",
    "class LogisticRegressionFromScratch:\n",
    "    \"\"\"\n",
    "    Logistic Regression classifier implemented from scratch using gradient descent\n",
    "    For multi-class classification using One-vs-Rest approach\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, regularization=None, lambda_reg=0.01):\n",
    "        \"\"\"\n",
    "        Initialize Logistic Regression classifier\n",
    "        \n",
    "        Parameters:\n",
    "        learning_rate: Step size for gradient descent\n",
    "        n_iterations: Number of training iterations\n",
    "        regularization: Type of regularization ('l2', 'l1', or None)\n",
    "        lambda_reg: Regularization strength\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.regularization = regularization\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.classes = None\n",
    "        self.classifiers = {}\n",
    "        self.cost_history = []\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        Sigmoid activation function\n",
    "        \n",
    "        Parameters:\n",
    "        z: Input value or array\n",
    "        \n",
    "        Returns:\n",
    "        sigmoid(z): Value between 0 and 1\n",
    "        \"\"\"\n",
    "        # Clip values to prevent overflow\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def cost_function(self, X, y, weights, bias):\n",
    "        \"\"\"\n",
    "        Calculate binary cross-entropy cost\n",
    "        \n",
    "        Parameters:\n",
    "        X: Features (n_samples, n_features)\n",
    "        y: Binary labels (n_samples,)\n",
    "        weights: Model weights\n",
    "        bias: Model bias\n",
    "        \n",
    "        Returns:\n",
    "        cost: Cross-entropy cost\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Calculate predictions\n",
    "        z = np.dot(X, weights) + bias\n",
    "        predictions = self.sigmoid(z)\n",
    "        \n",
    "        # Clip predictions to prevent log(0)\n",
    "        epsilon = 1e-7\n",
    "        predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "        \n",
    "        # Binary cross-entropy cost\n",
    "        cost = -(1/n_samples) * np.sum(\n",
    "            y * np.log(predictions) + (1 - y) * np.log(1 - predictions)\n",
    "        )\n",
    "        \n",
    "        # Add regularization term\n",
    "        if self.regularization == 'l2':\n",
    "            cost += (self.lambda_reg / (2 * n_samples)) * np.sum(weights ** 2)\n",
    "        elif self.regularization == 'l1':\n",
    "            cost += (self.lambda_reg / n_samples) * np.sum(np.abs(weights))\n",
    "            \n",
    "        return cost\n",
    "    \n",
    "    def gradient_descent(self, X, y, weights, bias):\n",
    "        \"\"\"\n",
    "        Perform one step of gradient descent\n",
    "        \n",
    "        Parameters:\n",
    "        X: Features (n_samples, n_features)\n",
    "        y: Binary labels (n_samples,)\n",
    "        weights: Current weights\n",
    "        bias: Current bias\n",
    "        \n",
    "        Returns:\n",
    "        weights: Updated weights\n",
    "        bias: Updated bias\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Forward propagation\n",
    "        z = np.dot(X, weights) + bias\n",
    "        predictions = self.sigmoid(z)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        dw = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "        db = (1/n_samples) * np.sum(predictions - y)\n",
    "        \n",
    "        # Add regularization to weight gradient\n",
    "        if self.regularization == 'l2':\n",
    "            dw += (self.lambda_reg / n_samples) * weights\n",
    "        elif self.regularization == 'l1':\n",
    "            dw += (self.lambda_reg / n_samples) * np.sign(weights)\n",
    "        \n",
    "        # Update parameters\n",
    "        weights = weights - self.learning_rate * dw\n",
    "        bias = bias - self.learning_rate * db\n",
    "        \n",
    "        return weights, bias\n",
    "    \n",
    "    def fit_binary(self, X, y):\n",
    "        \"\"\"\n",
    "        Train binary logistic regression\n",
    "        \n",
    "        Parameters:\n",
    "        X: Features (n_samples, n_features)\n",
    "        y: Binary labels (n_samples,)\n",
    "        \n",
    "        Returns:\n",
    "        weights: Trained weights\n",
    "        bias: Trained bias\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize parameters\n",
    "        weights = np.zeros(n_features)\n",
    "        bias = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for i in range(self.n_iterations):\n",
    "            # Calculate cost\n",
    "            cost = self.cost_function(X, y, weights, bias)\n",
    "            \n",
    "            # Gradient descent\n",
    "            weights, bias = self.gradient_descent(X, y, weights, bias)\n",
    "            \n",
    "            # Store cost for plotting\n",
    "            if i % 100 == 0:\n",
    "                self.cost_history.append(cost)\n",
    "                \n",
    "        return weights, bias\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train multi-class logistic regression using One-vs-Rest\n",
    "        \n",
    "        Parameters:\n",
    "        X_train: Training features (n_samples, n_features)\n",
    "        y_train: Training labels (n_samples,)\n",
    "        \"\"\"\n",
    "        self.classes = np.unique(y_train)\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        print(f\"Training {n_classes} binary classifiers (One-vs-Rest)...\")\n",
    "        \n",
    "        # Train a binary classifier for each class\n",
    "        for class_label in self.classes:\n",
    "            print(f\"  Training classifier for class {class_label}...\", end=\"\")\n",
    "            \n",
    "            # Create binary labels (1 for current class, 0 for others)\n",
    "            binary_labels = (y_train == class_label).astype(int)\n",
    "            \n",
    "            # Train binary classifier\n",
    "            weights, bias = self.fit_binary(X_train, binary_labels)\n",
    "            \n",
    "            # Store classifier\n",
    "            self.classifiers[class_label] = {'weights': weights, 'bias': bias}\n",
    "            print(\" Done\")\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict class probabilities\n",
    "        \n",
    "        Parameters:\n",
    "        X_test: Test features (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        probabilities: Array of class probabilities (n_samples, n_classes)\n",
    "        \"\"\"\n",
    "        n_samples = X_test.shape[0]\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        # Calculate scores for each class\n",
    "        scores = np.zeros((n_samples, n_classes))\n",
    "        \n",
    "        for i, class_label in enumerate(self.classes):\n",
    "            classifier = self.classifiers[class_label]\n",
    "            z = np.dot(X_test, classifier['weights']) + classifier['bias']\n",
    "            scores[:, i] = self.sigmoid(z)\n",
    "        \n",
    "        # Normalize scores to get probabilities (softmax-like)\n",
    "        probabilities = scores / np.sum(scores, axis=1, keepdims=True)\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict classes\n",
    "        \n",
    "        Parameters:\n",
    "        X_test: Test features (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        predictions: Array of predicted classes\n",
    "        \"\"\"\n",
    "        probabilities = self.predict_proba(X_test)\n",
    "        \n",
    "        # Choose class with highest probability\n",
    "        predicted_indices = np.argmax(probabilities, axis=1)\n",
    "        predictions = self.classes[predicted_indices]\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Handle data preprocessing tasks\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Calculate mean and standard deviation\n",
    "        \n",
    "        Parameters:\n",
    "        X: Features to fit\n",
    "        \"\"\"\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.std = np.std(X, axis=0)\n",
    "        # Prevent division by zero\n",
    "        self.std[self.std == 0] = 1\n",
    "        \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Standardize features\n",
    "        \n",
    "        Parameters:\n",
    "        X: Features to transform\n",
    "        \n",
    "        Returns:\n",
    "        X_scaled: Standardized features\n",
    "        \"\"\"\n",
    "        return (X - self.mean) / self.std\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Fit and transform in one step\n",
    "        \n",
    "        Parameters:\n",
    "        X: Features to fit and transform\n",
    "        \n",
    "        Returns:\n",
    "        X_scaled: Standardized features\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Split data into training and testing sets\n",
    "    \n",
    "    Parameters:\n",
    "    X: Features\n",
    "    y: Labels\n",
    "    test_size: Proportion of data for testing\n",
    "    random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    X_train, X_test, y_train, y_test: Split datasets\n",
    "    \"\"\"\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    n_test = int(n_samples * test_size)\n",
    "    \n",
    "    # Create shuffled indices\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    # Split indices\n",
    "    test_indices = indices[:n_test]\n",
    "    train_indices = indices[n_test:]\n",
    "    \n",
    "    # Split data\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: True labels\n",
    "    y_pred: Predicted labels\n",
    "    \n",
    "    Returns:\n",
    "    accuracy: Proportion of correct predictions\n",
    "    \"\"\"\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Create confusion matrix\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: True labels\n",
    "    y_pred: Predicted labels\n",
    "    \n",
    "    Returns:\n",
    "    matrix: Confusion matrix\n",
    "    \"\"\"\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    matrix = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    \n",
    "    for i, true_class in enumerate(classes):\n",
    "        for j, pred_class in enumerate(classes):\n",
    "            matrix[i, j] = np.sum((y_true == true_class) & (y_pred == pred_class))\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Generate classification report\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: True labels\n",
    "    y_pred: Predicted labels\n",
    "    \n",
    "    Returns:\n",
    "    report: Dictionary with metrics for each class\n",
    "    \"\"\"\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    report = {}\n",
    "    \n",
    "    for cls in classes:\n",
    "        # True positives, false positives, false negatives\n",
    "        tp = np.sum((y_true == cls) & (y_pred == cls))\n",
    "        fp = np.sum((y_true != cls) & (y_pred == cls))\n",
    "        fn = np.sum((y_true == cls) & (y_pred != cls))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        support = np.sum(y_true == cls)\n",
    "        \n",
    "        report[cls] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1-score': f1,\n",
    "            'support': support\n",
    "        }\n",
    "    \n",
    "    # Calculate weighted average\n",
    "    total_support = len(y_true)\n",
    "    avg_precision = sum(report[cls]['precision'] * report[cls]['support'] for cls in classes) / total_support\n",
    "    avg_recall = sum(report[cls]['recall'] * report[cls]['support'] for cls in classes) / total_support\n",
    "    avg_f1 = sum(report[cls]['f1-score'] * report[cls]['support'] for cls in classes) / total_support\n",
    "    \n",
    "    report['weighted avg'] = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'support': total_support\n",
    "    }\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "def cross_validation(model, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation\n",
    "    \n",
    "    Parameters:\n",
    "    model: Model to evaluate\n",
    "    X: Features\n",
    "    y: Labels\n",
    "    cv: Number of folds\n",
    "    \n",
    "    Returns:\n",
    "    scores: Array of accuracy scores for each fold\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    fold_size = n_samples // cv\n",
    "    scores = []\n",
    "    \n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    for fold in range(cv):\n",
    "        # Define fold boundaries\n",
    "        start = fold * fold_size\n",
    "        end = start + fold_size if fold < cv - 1 else n_samples\n",
    "        \n",
    "        # Split data\n",
    "        test_indices = indices[start:end]\n",
    "        train_indices = np.concatenate([indices[:start], indices[end:]])\n",
    "        \n",
    "        X_train_fold = X[train_indices]\n",
    "        y_train_fold = y[train_indices]\n",
    "        X_test_fold = X[test_indices]\n",
    "        y_test_fold = y[test_indices]\n",
    "        \n",
    "        # Train and evaluate\n",
    "        # Create new model instance for each fold\n",
    "        if isinstance(model, KNNFromScratch):\n",
    "            fold_model = KNNFromScratch(k=model.k)\n",
    "        else:\n",
    "            fold_model = LogisticRegressionFromScratch(\n",
    "                learning_rate=model.learning_rate,\n",
    "                n_iterations=model.n_iterations,\n",
    "                regularization=model.regularization,\n",
    "                lambda_reg=model.lambda_reg\n",
    "            )\n",
    "        \n",
    "        # Standardize data\n",
    "        scaler = DataPreprocessor()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_test_scaled = scaler.transform(X_test_fold)\n",
    "        \n",
    "        # Train and predict\n",
    "        fold_model.fit(X_train_scaled, y_train_fold)\n",
    "        predictions = fold_model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test_fold, predictions)\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "def find_best_k(X_train, y_train, k_range):\n",
    "    \"\"\"\n",
    "    Find the best k value for KNN using cross-validation\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Training features\n",
    "    y_train: Training labels\n",
    "    k_range: Range of k values to test\n",
    "    \n",
    "    Returns:\n",
    "    best_k: Optimal k value\n",
    "    scores: Dictionary of k values and their scores\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    for k in k_range:\n",
    "        print(f\"  Testing k={k}...\", end=\"\")\n",
    "        knn = KNNFromScratch(k=k)\n",
    "        cv_scores = cross_validation(knn, X_train, y_train, cv=5)\n",
    "        scores[k] = {\n",
    "            'mean': np.mean(cv_scores),\n",
    "            'std': np.std(cv_scores)\n",
    "        }\n",
    "        print(f\" Mean accuracy: {scores[k]['mean']:.4f}\")\n",
    "    \n",
    "    # Find best k\n",
    "    best_k = max(scores.keys(), key=lambda k: scores[k]['mean'])\n",
    "    \n",
    "    return best_k, scores\n",
    "\n",
    "\n",
    "def plot_results(knn_results, lr_results, k_scores=None):\n",
    "    \"\"\"\n",
    "    Create visualizations\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: K-value performance\n",
    "    if k_scores:\n",
    "        ax = axes[0, 0]\n",
    "        k_values = list(k_scores.keys())\n",
    "        mean_scores = [k_scores[k]['mean'] for k in k_values]\n",
    "        std_scores = [k_scores[k]['std'] for k in k_values]\n",
    "        \n",
    "        ax.errorbar(k_values, mean_scores, yerr=std_scores, marker='o', capsize=5)\n",
    "        ax.set_xlabel('K Value', fontsize=12)\n",
    "        ax.set_ylabel('Cross-Validation Accuracy', fontsize=12)\n",
    "        ax.set_title('KNN Performance vs K Value', fontsize=14, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Model Comparison\n",
    "    ax = axes[0, 1]\n",
    "    models = ['KNN', 'Logistic\\nRegression']\n",
    "    accuracies = [knn_results['accuracy'], lr_results['accuracy']]\n",
    "    \n",
    "    bars = ax.bar(models, accuracies, color=['skyblue', 'lightcoral'], edgecolor='black', linewidth=2)\n",
    "    ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "    ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "               f'{acc:.3f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Plot 3: Quality Distribution\n",
    "    ax = axes[0, 2]\n",
    "    quality_counts = df['quality'].value_counts().sort_index()\n",
    "    ax.bar(quality_counts.index, quality_counts.values, color='green', alpha=0.7)\n",
    "    ax.set_xlabel('Wine Quality', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_title('Wine Quality Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 4: KNN Confusion Matrix\n",
    "    ax = axes[1, 0]\n",
    "    sns.heatmap(knn_results['confusion_matrix'], annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel('Predicted', fontsize=12)\n",
    "    ax.set_ylabel('Actual', fontsize=12)\n",
    "    ax.set_title('KNN Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Plot 5: Logistic Regression Confusion Matrix\n",
    "    ax = axes[1, 1]\n",
    "    sns.heatmap(lr_results['confusion_matrix'], annot=True, fmt='d', cmap='Reds', ax=ax)\n",
    "    ax.set_xlabel('Predicted', fontsize=12)\n",
    "    ax.set_ylabel('Actual', fontsize=12)\n",
    "    ax.set_title('Logistic Regression Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Plot 6: Per-Class Performance\n",
    "    ax = axes[1, 2]\n",
    "    classes = sorted(df['quality'].unique())\n",
    "    \n",
    "    knn_f1 = [knn_results['report'][cls]['f1-score'] for cls in classes]\n",
    "    lr_f1 = [lr_results['report'][cls]['f1-score'] for cls in classes]\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, knn_f1, width, label='KNN', color='skyblue')\n",
    "    ax.bar(x + width/2, lr_f1, width, label='Logistic Regression', color='lightcoral')\n",
    "    \n",
    "    ax.set_xlabel('Wine Quality', fontsize=12)\n",
    "    ax.set_ylabel('F1-Score', fontsize=12)\n",
    "    ax.set_title('Per-Class F1-Score Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('wine_from_scratch_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Results visualization saved as 'wine_from_scratch_results.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03c0c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "               WINE QUALITY PREDICTION FROM SCRATCH\n",
      "                    KNN & Logistic Regression\n",
      "================================================================================\n",
      "\n",
      "1. DATA PREPARATION\n",
      "----------------------------------------\n",
      "Removed 125 duplicate rows\n",
      "Dataset shape: (1018, 11)\n",
      "Number of classes: 6\n",
      "Class distribution: {np.int64(3): np.int64(6), np.int64(4): np.int64(33), np.int64(5): np.int64(433), np.int64(6): np.int64(409), np.int64(7): np.int64(122), np.int64(8): np.int64(15)}\n",
      "Training set: (814, 11)\n",
      "Test set: (204, 11)\n",
      "Features standardized (mean=0, std=1)\n",
      "\n",
      "2. K-NEAREST NEIGHBORS\n",
      "----------------------------------------\n",
      "Finding optimal k value using cross-validation...\n",
      "  Testing k=3... Mean accuracy: 0.5248\n",
      "  Testing k=5... Mean accuracy: 0.5506\n",
      "  Testing k=7... Mean accuracy: 0.5651\n",
      "  Testing k=9... Mean accuracy: 0.5762\n",
      "  Testing k=11... Mean accuracy: 0.5934\n",
      "  Testing k=13... Mean accuracy: 0.5884\n",
      "  Testing k=15... Mean accuracy: 0.5945\n",
      "  Testing k=17... Mean accuracy: 0.5614\n",
      "  Testing k=19... Mean accuracy: 0.5763\n",
      "\n",
      "✓ Best k value: 15\n",
      "  Cross-validation accuracy: 0.5945 (+/- 0.0342)\n",
      "\n",
      "Training final KNN model...\n",
      "KNN Test Accuracy: 0.5147\n",
      "\n",
      "KNN Classification Report:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 185\u001b[39m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m knn_model, lr_model, scaler\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     knn_model, lr_model, scaler = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mKNN Classification Report:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mknn_report\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m()):\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m != \u001b[33m'\u001b[39m\u001b[33mweighted avg\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     69\u001b[39m         metrics = knn_report[\u001b[38;5;28mcls\u001b[39m]\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \" * 15 + \"WINE QUALITY PREDICTION FROM SCRATCH\")\n",
    "    print(\" \" * 20 + \"KNN & Logistic Regression\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"\\n1. DATA PREPARATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Drop Id column if it exists\n",
    "    if 'Id' in df.columns:\n",
    "        df.drop('Id', axis=1, inplace=True)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    initial_size = len(df)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Removed {initial_size - len(df)} duplicate rows\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('quality', axis=1).values\n",
    "    y = df['quality'].values\n",
    "    \n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "    print(f\"Class distribution: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set: {X_train.shape}\")\n",
    "    print(f\"Test set: {X_test.shape}\")\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = DataPreprocessor()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Features standardized (mean=0, std=1)\")\n",
    "    \n",
    "    # KNN Implementation\n",
    "    print(\"\\n2. K-NEAREST NEIGHBORS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Find best k value\n",
    "    print(\"Finding optimal k value using cross-validation...\")\n",
    "    k_range = range(3, 21, 2)\n",
    "    best_k, k_scores = find_best_k(X_train_scaled, y_train, k_range)\n",
    "    print(f\"\\n✓ Best k value: {best_k}\")\n",
    "    print(f\"  Cross-validation accuracy: {k_scores[best_k]['mean']:.4f} (+/- {k_scores[best_k]['std']:.4f})\")\n",
    "    \n",
    "    # Train final KNN model\n",
    "    print(\"\\nTraining final KNN model...\")\n",
    "    knn_model = KNNFromScratch(k=best_k)\n",
    "    knn_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate KNN\n",
    "    knn_predictions = knn_model.predict(X_test_scaled)\n",
    "    knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "    knn_cm = confusion_matrix(y_test, knn_predictions)\n",
    "    knn_report = classification_report(y_test, knn_predictions)\n",
    "    \n",
    "    print(f\"KNN Test Accuracy: {knn_accuracy:.4f}\")\n",
    "    print(\"\\nKNN Classification Report:\")\n",
    "    print(\"-\" * 40)\n",
    "    for cls in sorted(knn_report.keys()):\n",
    "        if cls != 'weighted avg':\n",
    "            metrics = knn_report[cls]\n",
    "            print(f\"Class {cls}: Precision={metrics['precision']:.3f}, \"\n",
    "                  f\"Recall={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}, \"\n",
    "                  f\"Support={metrics['support']}\")\n",
    "    \n",
    "    # Logistic Regression Implementation\n",
    "    print(\"\\n3. LOGISTIC REGRESSION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train Logistic Regression\n",
    "    print(\"Training Logistic Regression with gradient descent...\")\n",
    "    lr_model = LogisticRegressionFromScratch(\n",
    "        learning_rate=0.1,\n",
    "        n_iterations=1000,\n",
    "        regularization='l2',\n",
    "        lambda_reg=0.01\n",
    "    )\n",
    "    lr_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate Logistic Regression\n",
    "    lr_predictions = lr_model.predict(X_test_scaled)\n",
    "    lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "    lr_cm = confusion_matrix(y_test, lr_predictions)\n",
    "    lr_report = classification_report(y_test, lr_predictions)\n",
    "    \n",
    "    print(f\"\\nLogistic Regression Test Accuracy: {lr_accuracy:.4f}\")\n",
    "    print(\"\\nLogistic Regression Classification Report:\")\n",
    "    print(\"-\" * 40)\n",
    "    for cls in sorted(lr_report.keys()):\n",
    "        if cls != 'weighted avg':\n",
    "            metrics = lr_report[cls]\n",
    "            print(f\"Class {cls}: Precision={metrics['precision']:.3f}, \"\n",
    "                  f\"Recall={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}, \"\n",
    "                  f\"Support={metrics['support']}\")\n",
    "    \n",
    "    # Model Comparison\n",
    "    print(\"\\n4. MODEL COMPARISON\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"KNN Accuracy: {knn_accuracy:.4f}\")\n",
    "    print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
    "    \n",
    "    if knn_accuracy > lr_accuracy:\n",
    "        print(f\"\\n✓ KNN performs better by {(knn_accuracy - lr_accuracy)*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"\\n✓ Logistic Regression performs better by {(lr_accuracy - knn_accuracy)*100:.2f}%\")\n",
    "    \n",
    "    # Weighted average metrics\n",
    "    print(\"\\nWeighted Average Metrics:\")\n",
    "    print(f\"KNN - Precision: {knn_report['weighted avg']['precision']:.3f}, \"\n",
    "          f\"Recall: {knn_report['weighted avg']['recall']:.3f}, \"\n",
    "          f\"F1: {knn_report['weighted avg']['f1-score']:.3f}\")\n",
    "    print(f\"LR  - Precision: {lr_report['weighted avg']['precision']:.3f}, \"\n",
    "          f\"Recall: {lr_report['weighted avg']['recall']:.3f}, \"\n",
    "          f\"F1: {lr_report['weighted avg']['f1-score']:.3f}\")\n",
    "    \n",
    "    # Store results\n",
    "    knn_results = {\n",
    "        'accuracy': knn_accuracy,\n",
    "        'confusion_matrix': knn_cm,\n",
    "        'report': knn_report\n",
    "    }\n",
    "    \n",
    "    lr_results = {\n",
    "        'accuracy': lr_accuracy,\n",
    "        'confusion_matrix': lr_cm,\n",
    "        'report': lr_report\n",
    "    }\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"\\n5. CREATING VISUALIZATIONS\")\n",
    "    print(\"-\" * 40)\n",
    "    plot_results(knn_results, lr_results, k_scores)\n",
    "    \n",
    "    # Example prediction\n",
    "    print(\"\\n6. EXAMPLE PREDICTION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Use first test sample\n",
    "    sample_idx = 0\n",
    "    sample_features = X_test_scaled[sample_idx:sample_idx+1]\n",
    "    actual_quality = y_test[sample_idx]\n",
    "    \n",
    "    # Get predictions from both models\n",
    "    knn_pred = knn_model.predict(sample_features)[0]\n",
    "    lr_pred = lr_model.predict(sample_features)[0]\n",
    "    \n",
    "    # Get probabilities\n",
    "    knn_proba = knn_model.predict_proba(sample_features)[0]\n",
    "    lr_proba = lr_model.predict_proba(sample_features)[0]\n",
    "    \n",
    "    print(f\"Sample wine features (standardized):\")\n",
    "    feature_names = df.drop('quality', axis=1).columns\n",
    "    for name, value in zip(feature_names, X_test[sample_idx]):\n",
    "        print(f\"  {name}: {value:.3f}\")\n",
    "    \n",
    "    print(f\"\\nActual Quality: {actual_quality}\")\n",
    "    print(f\"KNN Prediction: {knn_pred}\")\n",
    "    print(f\"Logistic Regression Prediction: {lr_pred}\")\n",
    "    \n",
    "    print(\"\\nKNN Probabilities:\")\n",
    "    for cls, prob in zip(np.unique(y_train), knn_proba):\n",
    "        if prob > 0:\n",
    "            print(f\"  Quality {cls}: {prob:.3f}\")\n",
    "    \n",
    "    print(\"\\nLogistic Regression Probabilities:\")\n",
    "    for cls, prob in zip(lr_model.classes, lr_proba):\n",
    "        print(f\"  Quality {cls}: {prob:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✓ Model training and evaluation complete!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return knn_model, lr_model, scaler\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    knn_model, lr_model, scaler = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3e4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
